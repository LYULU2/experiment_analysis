{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55ad906",
   "metadata": {},
   "source": [
    "## unzip and parse fit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a996a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile  #zipfile.is_zipfile(filename)\n",
    "import os\n",
    "import fitparse\n",
    "import csv\n",
    "import pytz\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce10a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(path):\n",
    "    files = os.listdir(path)\n",
    "    fit_files = [file for file in files if file[-4:].lower()=='.fit']\n",
    "    for file in fit_files:\n",
    "        new_filename = file[:-4] + '.csv'\n",
    "        '''\n",
    "        if os.path.exists(new_filename):\n",
    "            continue\n",
    "        '''\n",
    "        fitfile = fitparse.FitFile(os.path.join(path,file),  \n",
    "            data_processor=fitparse.StandardUnitsDataProcessor())\n",
    "        if re.findall(r\"WELLNESS\\Z\", file[:-4]):\n",
    "            write_fitfile_to_csv(fitfile, os.path.join(path,new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54740e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowed_fields = ['serial_number','time_created','manufacturer',\n",
    "#                   'garmin_product','number','type','timestamp[s]',\n",
    "#                   'serial_number','manufacturer','garmin_product',\n",
    "#                   'software_version','version','timestamp[s]',\n",
    "#                   'local_timestamp[s]','cycles_to_distance[m/cycle]',\n",
    "#                   'cycles_to_calories[kcal/cycle]','unknown',\n",
    "#                   'resting_metabolic_rate[kcal / day]','activity_type',\n",
    "#                   'timestamp[s]','unknown','timestamp[s]','enabled',\n",
    "#                   'unknown','stress_level_time','stress_level_value',\n",
    "#                   'unknown'\n",
    "#                  ]\n",
    "\n",
    "#final fields recorded\n",
    "allowed_fields = ['timestamp_16','heart_rate','stress_level_time','stress_level_value']\n",
    "\n",
    "#required_fields = ['serial_number', 'time_created']\n",
    "\n",
    "UTC = pytz.UTC\n",
    "CST = pytz.timezone('US/Pacific')\n",
    "def write_fitfile_to_csv(fitfile, output_file='test_output.csv'):\n",
    "    messages = fitfile.messages\n",
    "    data = []\n",
    "    for m in messages:\n",
    "        skip=False\n",
    "        if not hasattr(m, 'fields'):\n",
    "            continue\n",
    "        fields = m.fields\n",
    "        #check for important data types\n",
    "        mdata = {}\n",
    "        for field in fields:\n",
    "            if field.name in allowed_fields:\n",
    "                if field.name=='stress_level_time':\n",
    "                    mdata[field.name] = UTC.localize(field.value).astimezone(CST)\n",
    "                else:\n",
    "                    mdata[field.name] = field.value\n",
    "        #for rf in required_fields:\n",
    "        #    if rf not in mdata:\n",
    "        #        skip=True\n",
    "        if not skip:\n",
    "            data.append(mdata)\n",
    "    #write to csv\n",
    "    with open(output_file, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(allowed_fields)\n",
    "        for entry in data:\n",
    "            writer.writerow([ str(entry.get(k, '')) for k in allowed_fields])\n",
    "    #print('wrote %s' % output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "558c92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_studio(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        sub_file_path = os.path.join(path,file)\n",
    "        \n",
    "        if not os.path.isdir(sub_file_path):\n",
    "            continue\n",
    "        sub_files = os.listdir(sub_file_path)\n",
    "        for sub_file in sub_files:\n",
    "            sub_sub_file_path = os.path.join(path,file,sub_file)\n",
    "            if not os.path.isdir(sub_sub_file_path):\n",
    "                continue\n",
    "            sub_sub_files = os.listdir(sub_sub_file_path)\n",
    "            for sub_sub_file in sub_sub_files:\n",
    "                \n",
    "                bottom_file_path = os.path.join(path,file,sub_file, sub_sub_file)\n",
    "                if not os.path.isdir(bottom_file_path):\n",
    "                    continue\n",
    "                bottom_files = os.listdir(bottom_file_path)\n",
    "                for bottom_file in bottom_files:\n",
    "                    path_to_zip_file = os.path.join(path,file,sub_file, sub_sub_file, bottom_file)\n",
    "                    if zipfile.is_zipfile(path_to_zip_file):\n",
    "                        #print(bottom_file)\n",
    "                        directory_to_extract_to = path_to_zip_file[:-4]\n",
    "                        with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "                            zip_ref.extractall(directory_to_extract_to)\n",
    "                        parse_file(directory_to_extract_to) # parse the fit files to csv files\n",
    "        \n",
    "\n",
    "read_file_studio(\"/Users/luerlyu/Desktop/Experimental Data/Physiological data/Studio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e91db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_wsp(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        sub_file_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(sub_file_path):\n",
    "            continue\n",
    "        sub_files = os.listdir(sub_file_path)\n",
    "        for sub_file in sub_files:\n",
    "            bottom_file_path = os.path.join(path,file,sub_file)\n",
    "            if not os.path.isdir(bottom_file_path):\n",
    "                continue\n",
    "            bottom_files = os.listdir(bottom_file_path)\n",
    "            for bottom_file in bottom_files:\n",
    "                path_to_zip_file = os.path.join(path,file,sub_file, bottom_file)\n",
    "                if zipfile.is_zipfile(path_to_zip_file):\n",
    "                    directory_to_extract_to = path_to_zip_file[:-4]\n",
    "                    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "                        zip_ref.extractall(directory_to_extract_to)\n",
    "                    parse_file(directory_to_extract_to) # parse the fit files to csv files\n",
    "read_file_wsp(\"/Users/luerlyu/Desktop/Experimental Data/Physiological data/WSP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d96e17",
   "metadata": {},
   "source": [
    "No zip file for the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5991eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_file('/Users/luerlyu/Desktop/Experimental Data/Physiological data/Studio/F/Afro/1111/2022-11-11')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986d640",
   "metadata": {},
   "source": [
    "## parse eda by specific time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1fddf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(unix):\n",
    "    dt = datetime.datetime.fromtimestamp(unix/1e3)\n",
    "    return dt.replace(microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5364ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_time_eda(path):\n",
    "    eda_df = pd.read_csv(path)\n",
    "    eda_df.rename(columns = {\"Unix Timestamp (UTC)\":\"time\"}, inplace = True)\n",
    "    eda_df[\"time\"] = eda_df[\"time\"].map(to_date)\n",
    "    st_time = eda_df[\"time\"].iloc[0]\n",
    "    end_time = eda_df[\"time\"].iloc[-1]\n",
    "    #make a 10 min interval\n",
    "    interval_df = pd.DataFrame({\"time\":pd.date_range(st_time, end_time, freq='10T')})\n",
    "    res_df = eda_df.merge(interval_df, on=\"time\")\n",
    "    res_df = res_df.groupby([\"time\"]).mean()\n",
    "    path_to_new_file = path[:-4]+\"_processed.csv\"\n",
    "    res_df.to_csv(path_to_new_file, index=\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37888864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_time_temp(path):\n",
    "    temp_df = pd.read_csv(path)\n",
    "    temp_df.rename(columns = {\"Unix Timestamp (UTC)\":\"time\"}, inplace = True)\n",
    "    try:\n",
    "        temp_df[\"time\"] = temp_df[\"time\"].map(to_date)\n",
    "    except:\n",
    "        print(path)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    res_df = temp_df.groupby(pd.Grouper(key=\"time\", freq=\"10min\")).mean()\n",
    "    path_to_new_file = path[:-4]+\"_processed.csv\"\n",
    "    res_df.to_csv(path_to_new_file, index=\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "29d8a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luerlyu/Desktop/Experimental Data/Physiological data/Studio/F/Afro/1111/temp.csv\n"
     ]
    }
   ],
   "source": [
    "def select_time_studio(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        sub_file_path = os.path.join(path,file)\n",
    "        \n",
    "        if not os.path.isdir(sub_file_path):\n",
    "            continue\n",
    "        sub_files = os.listdir(sub_file_path)\n",
    "        for sub_file in sub_files:\n",
    "            sub_sub_file_path = os.path.join(path,file,sub_file)\n",
    "            if not os.path.isdir(sub_sub_file_path):\n",
    "                continue\n",
    "            sub_sub_files = os.listdir(sub_sub_file_path)\n",
    "            for sub_sub_file in sub_sub_files:\n",
    "                \n",
    "                bottom_file_path = os.path.join(path,file,sub_file, sub_sub_file)\n",
    "                if not os.path.isdir(bottom_file_path):\n",
    "                    continue\n",
    "                bottom_files = os.listdir(bottom_file_path)\n",
    "                for bottom_file in bottom_files:\n",
    "                    if bottom_file == \"eda.csv\":\n",
    "                        path_to_eda_file = os.path.join(path,file,sub_file, sub_sub_file, bottom_file)\n",
    "                        select_time_eda(path_to_eda_file)\n",
    "                    elif bottom_file == \"temp.csv\":\n",
    "                        path_to_temp_file = os.path.join(path,file,sub_file, sub_sub_file, bottom_file)\n",
    "                        select_time_temp(path_to_temp_file)\n",
    "        \n",
    "\n",
    "select_time_studio(\"/Users/luerlyu/Desktop/Experimental Data/Physiological data/Studio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d338a735",
   "metadata": {},
   "source": [
    "'Experimental Data/Physiological data/Studio/F/Afro/1111/temp.csv' was processed in different wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f1eb6e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_time_wsp(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        sub_file_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(sub_file_path):\n",
    "            continue\n",
    "        sub_files = os.listdir(sub_file_path)\n",
    "        for sub_file in sub_files:\n",
    "            bottom_file_path = os.path.join(path,file,sub_file)\n",
    "            if not os.path.isdir(bottom_file_path):\n",
    "                continue\n",
    "            bottom_files = os.listdir(bottom_file_path)\n",
    "            for bottom_file in bottom_files:\n",
    "                if bottom_file == \"eda.csv\":\n",
    "                    path_to_eda_file = os.path.join(path,file,sub_file,  bottom_file)\n",
    "                    select_time_eda(path_to_eda_file)\n",
    "                elif bottom_file == \"temp.csv\":\n",
    "                    path_to_temp_file = os.path.join(path,file,sub_file, bottom_file)\n",
    "                    select_time_df(path_to_temp_file)\n",
    "select_time_wsp(\"/Users/luerlyu/Desktop/Experimental Data/Physiological data/WSP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aed417",
   "metadata": {},
   "source": [
    "## handle heart rate time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f19b798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_time(path):\n",
    "    files = os.listdir(path)\n",
    "    csv_files = [file for file in files if file[-4:].lower()=='.csv' and re.findall(r\"WELLNESS\\Z\", file[:-4])]\n",
    "    #for each heart rate entry, replace with the prev timestamp\n",
    "    for csv in csv_files:\n",
    "        df = pd.read_csv(os.path.join(path,csv))\n",
    "        # if processed, skip\n",
    "        if len(df.columns) ==3:\n",
    "            continue\n",
    "        for i in range(1,len(df)):\n",
    "            try:\n",
    "                k = pd.isnull(df.loc[i, 'heart_rate'])\n",
    "            except:\n",
    "                print(path, csv)\n",
    "                return \n",
    "            if not pd.isnull(df.loc[i, 'heart_rate']):\n",
    "                idx = i\n",
    "                while idx>=1 and pd.isnull(df.loc[idx-1, 'stress_level_value']):\n",
    "                    idx-=1\n",
    "                df.loc[idx-1, 'heart_rate'] = df.loc[i, 'heart_rate']\n",
    "                #df=df.drop(df.index[i])\n",
    "                df.loc[i, 'heart_rate'] = np.nan\n",
    "            \n",
    "        df = df.rename(columns={\"stress_level_time\": \"timestamp\"})\n",
    "        df = df.drop(['timestamp_16'], axis=1)\n",
    "        df.to_csv(os.path.join(path,csv), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efa0d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_file_studio(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        sub_file_path = os.path.join(path,file)\n",
    "        \n",
    "        if not os.path.isdir(sub_file_path):\n",
    "            continue\n",
    "        sub_files = os.listdir(sub_file_path)\n",
    "        for sub_file in sub_files:\n",
    "            sub_sub_file_path = os.path.join(path,file,sub_file)\n",
    "            if not os.path.isdir(sub_sub_file_path):\n",
    "                continue\n",
    "            sub_sub_files = os.listdir(sub_sub_file_path)\n",
    "            for sub_sub_file in sub_sub_files:\n",
    "                \n",
    "                bottom_file_path = os.path.join(path,file,sub_file, sub_sub_file)\n",
    "                if not os.path.isdir(bottom_file_path):\n",
    "                    continue\n",
    "                bottom_files = os.listdir(bottom_file_path)\n",
    "                for bottom_file in bottom_files:\n",
    "                    path_to_unzipped_file = os.path.join(path,file,sub_file, sub_sub_file, bottom_file)\n",
    "                    if os.path.isdir(path_to_unzipped_file):\n",
    "                        handle_time(path_to_unzipped_file) # combine the csv files\n",
    "        \n",
    "\n",
    "handle_file_studio(\"/Users/luerlyu/Desktop/Experimental Data/Physiological data/Studio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fe5cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_file_wsp(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        sub_file_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(sub_file_path):\n",
    "            continue\n",
    "        sub_files = os.listdir(sub_file_path)\n",
    "        for sub_file in sub_files:\n",
    "            bottom_file_path = os.path.join(path,file,sub_file)\n",
    "            if not os.path.isdir(bottom_file_path):\n",
    "                continue\n",
    "            bottom_files = os.listdir(bottom_file_path)\n",
    "            for bottom_file in bottom_files:\n",
    "                path_to_unzipped_file = os.path.join(path,file,sub_file, bottom_file)\n",
    "                if os.path.isdir(path_to_unzipped_file):\n",
    "                    handle_time(path_to_unzipped_file) # combine the csv files\n",
    "handle_file_wsp(\"/Users/luerlyu/Desktop/Experimental Data/Physiological data/WSP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc630e39",
   "metadata": {},
   "source": [
    "## combine the wellness csv files into \"WELLNESS_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8e9ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_file(path):\n",
    "    files = os.listdir(path)\n",
    "    csv_files = [file for file in files if file[-4:].lower()=='.csv' and re.findall(r\"WELLNESS\\Z\", file[:-4])]\n",
    "    combined_df = pd.DataFrame(columns=['heart_rate','timestamp','stress_level_value'])\n",
    "    for csv in csv_files:\n",
    "        df = pd.read_csv(os.path.join(path,csv))\n",
    "        df.dropna(how='all',inplace=True) #removing empty cells\n",
    "        combined_df = pd.concat([combined_df, df])\n",
    "    #combined_df['stress_level_time'] = combined_df['stress_level_time'].astype('Int64')\n",
    "    combined_df.drop(combined_df[(combined_df['stress_level_value'] <=0)].index, inplace=True)\n",
    "    combined_df = combined_df.sort_values(by=['timestamp'], ascending=True)\n",
    "    combined_df.to_csv(os.path.join(path,'WELLNESS_combined.csv'), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "044303da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_file_studio(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        sub_file_path = os.path.join(path,file)\n",
    "        \n",
    "        if not os.path.isdir(sub_file_path):\n",
    "            continue\n",
    "        sub_files = os.listdir(sub_file_path)\n",
    "        for sub_file in sub_files:\n",
    "            sub_sub_file_path = os.path.join(path,file,sub_file)\n",
    "            if not os.path.isdir(sub_sub_file_path):\n",
    "                continue\n",
    "            sub_sub_files = os.listdir(sub_sub_file_path)\n",
    "            for sub_sub_file in sub_sub_files:\n",
    "                \n",
    "                bottom_file_path = os.path.join(path,file,sub_file, sub_sub_file)\n",
    "                if not os.path.isdir(bottom_file_path):\n",
    "                    continue\n",
    "                bottom_files = os.listdir(bottom_file_path)\n",
    "                for bottom_file in bottom_files:\n",
    "                    path_to_unzipped_file = os.path.join(path,file,sub_file, sub_sub_file, bottom_file)\n",
    "                    if os.path.isdir(path_to_unzipped_file):\n",
    "                        combine_file(path_to_unzipped_file) # combine the csv files\n",
    "        \n",
    "\n",
    "combine_file_studio(\"/Users/luerlyu/Desktop/Experimental Data/Physiological data/Studio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbdc927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_file_wsp(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        sub_file_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(sub_file_path):\n",
    "            continue\n",
    "        sub_files = os.listdir(sub_file_path)\n",
    "        for sub_file in sub_files:\n",
    "            bottom_file_path = os.path.join(path,file,sub_file)\n",
    "            if not os.path.isdir(bottom_file_path):\n",
    "                continue\n",
    "            bottom_files = os.listdir(bottom_file_path)\n",
    "            for bottom_file in bottom_files:\n",
    "                path_to_unzipped_file = os.path.join(path,file,sub_file, bottom_file)\n",
    "                if os.path.isdir(path_to_unzipped_file):\n",
    "                    combine_file(path_to_unzipped_file) # combine the csv files\n",
    "combine_file_wsp(\"/Users/luerlyu/Desktop/Experimental Data/Physiological data/WSP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83cd32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
